---
title: "GDP Prediction"
author: "Nikhil Gupta"
date: "`r Sys.time()`"
output:
  github_document: 
    toc: yes
    toc_depth: 6
  word_document:
    toc: yes
    toc_depth: '6'
  html_document:
    toc: yes
    toc_depth: 6
    toc_float: yes
always_allow_html: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Setup
```{r message=FALSE, warning=FALSE}
library(tswge)
library(tswgewrapped)
library(tidyverse)
library(ggplot2)
library(tseries)
```

```{r}
data = read.csv("../data/economic_indicators_all_ex_3mo_china.csv")
data %>% glimpse()
```

```{r}
x = data$gdp_change
```

```{r}
px = plotts.sample.wge(x)
```

## Stationarity

```{r}
tswgewrapped::check_stationarity(x)
```

### Condition 1

* Looks like there is a slight trend in the data with the mean moving down over time. This would be expected. As a country is growing, its GDP is expected to be high. As it becomes a more developed economy, the GDP settles at a lower but steadier value.
* The ACF plots shows extended autocorrelations although there is also a hint of exponentially decaying behavior. Hence, this trend (wanderig behavior) could be a result of a stationary AR process with positive phi values or it could be a result of a non-stationaty ARIMA like process. 
* **In summary, the mean is changing over time (wandering behavior) and based on the ACFs, this could be coming from either a stationary or a non stationary process.**


### Condition 2

* Since we have only 1 realization, it is hard to say whether the varaince is different at different time points. 
* However we can make some important observations from this realization and domain knowledge. We see that in the initial part of the graph there is more volatility in the GDP numbers compared to the second half of the graph. This is again expected based on domain knowledge. Just as a developing economy has a higher GDP change value per quarter in general, this comes with a higher volatility. As an economy becomes more developed, not only does the GDP settle to a lower value in general but also the volatility decreases as well.
* Given the above observations, there may be some hints that condition 2 has not been met


### Condition 3

* Both the first half and second half ACFs show a damped exponential behavior for the first few lags although the second half ACFs take longer to die down. Also, the 1st half ACF shows higher values at lags of 9, 10 and 11 compared to the second half. It is also interesting to see that neither the firs half nor the second half ACF matches the full data ACF. There is enough evience here to indicate that the data is not stationary.


### Conclusion

* Given the above analysis, there is a good chance that this data is not coming from a stationary process, although there were some hints (when looking at the mean) that it could have resulted from a stationary AR process. In order to completely eliminate the possibility that this may be coming from a stationary process, we will conduct an initial analysis with a stationary model.

## Stationary Model

### Setup

```{r}
n.ahead = 2
batch_size = 50 ## 12 years to predict the next 2 quarters
```

### Model ID

```{r}
aicbic(x, p = 0:5, q = 0:2, merge = TRUE, sort_by = 'bic', silent = TRUE)
```

### ARMA(2,1) Parameter Estimation
```{r}
est.arma.2.1 = est.arma.wge(x, p = 2, q = 1)
```

```{r}
est.arma.2.1$theta
```

**OBSERVATIONS**

* This clears a lot of confusion. **Even when fitting a stationary ARMA model, we get an estimated root of 0.9928 in the factor table which is very close to 1 (non stationary)**. Hence the confusion that we had before can be cleared now. The data most definitely is coming from a non stationary process. For the sake of completeness, we will continue modeling with this stationary model and see how well it performs.



## Non Stationary Model

Next we will evaluate this as a non stationary model.



### Model ID

An overfit table should show the non-stationary characteristics.
The overfit table with $p = 15$ has a root with absolute reciprocal of 0.9676, which is suggestive of a unit root.

```{r}
vals = overfit(x, p = 15, type = 'burg')
```

Because of the extended autocorrelations in the data, we will take the first difference and check the resultant data for stationarity.

```{r}
dif1 = artrans.wge(x, phi.tr = 1)
px = plotts.sample.wge(dif1)
```

* ACF is indicatove of a MA(1) model with positive theta since most ACFs die down after lag = 1 and there is a dip in the Spectral Density at f = 0.


```{r}
tswgewrapped::check_stationarity(dif1)
```

```{r}
aicbic(dif1, p = 0:5, q = 0:2, merge = TRUE, sort_by = 'bic', silent = TRUE)
```

### MA(1) Parameter Estimation
```{r}
est.arima.0.1.1.0 = est.arma.wge(dif1, p = 0, q = 1)
```


```{r}
factor.wge(est.arima.0.1.1.0$theta)
```


## Visualizing Model Comparison


```{r}
models = list("ARMA(2,1)" = list(phi = est.arma.2.1$phi,
                                 theta = est.arma.2.1$theta,
                                 vara = est.arma.2.1$avar,
                                 res = est.arma.2.1$res,
                                 sliding_ase = TRUE),
              "ARIMA(0,1,1) s = 0" = list(phi = est.arima.0.1.1.0$phi,
                                     theta = est.arima.0.1.1.0$theta,
                                     d = 1,
                                     s = 0,
                                     vara = est.arima.0.1.1.0$avar,
                                     res = est.arima.0.1.1.0$res,
                                     sliding_ase = TRUE)
              )
```


```{r}
mdl_compare = tswgewrapped::ModelCompareUnivariate$new(data = x, mdl_list = models,
                                                       n.ahead = n.ahead, batch_size = batch_size)
```

### Compare Residuals for White Noise
```{r}
table = mdl_compare$evaluate_residuals()
print(table)
```


**It looks like the residuals are not white noise so we have not captured all the signal in the model. Maybe we can do better by looking at higher ordered models.**

### Compare Multiple Realizations

```{r fig.height=8, fig.width=8, message=FALSE, warning=FALSE}
mdl_compare$plot_multiple_realizations(n.realizations = 4, seed = 100, plot = "realization", scales = 'fixed')
```

```{r fig.height=4, message=FALSE, warning=FALSE}
mdl_compare$plot_multiple_realizations(n.realizations = 4, seed = 100, plot = c("acf", "spectrum"), scales = 'fixed')
```

### Compare Simple Forecasts
```{r fig.height=4, fig.width=12}
mdl_compare$plot_simple_forecasts(lastn = FALSE, limits = FALSE)
```

### ASE values across Batches
```{r message=FALSE, warning=FALSE}
ASEs = mdl_compare$get_tabular_metrics(ases = TRUE)
print(ASEs)
```

```{r}
ASEs %>% 
  group_by(Model) %>% 
  summarise(ASE_mean = mean(ASE),
            ASE_median = median(ASE),
            ASE_sd = sd(ASE),
            num_batches = n())
```

```{r message=FALSE, warning=FALSE}
mdl_compare$plot_histogram_ases()
```

### Forecasts across Batches

```{r, warning=FALSE, fig.height=4, fig.width=10}
mdl_compare$plot_batch_forecasts(only_sliding = TRUE)
```

```{r, warning=FALSE, fig.height=4, fig.width=10}
mdl_compare$plot_batch_ases(only_sliding = TRUE)
```

```{r}
forecasts = mdl_compare$get_tabular_metrics(ases = FALSE)
print(forecasts)
```

### Statistical Comparison
```{r}
mdl_compare$statistical_compare()  
```

## Higher ordered Models

### Stationary Model

Since the ARMA(2, 1) does not appear to be sufficient to whiten the residuals, 
a higher order model, ARMA(13, 1) was fit.
The models suggested by BIC are not sufficient to whiten the residuals.

```{r}
aicbic(x, p = 0:16, silent = T, merge = TRUE, sort_by = 'aic')
```

#### ARMA(13, 1) Parameter Estimation

```{r}
est.arma.13.1 <- est.arma.wge(x, p = 13, q = 1)
```

```{r}
factor.wge(est.arma.13.1$theta)
```

#### Factored Form

```{r}
est.arma.13.1$avar
```

**(1-0.993$B$)(1-0.604$B$+0.888$B^2$)(1+1.794$B$+0.878$B^2$)(1+0.539$B$+0.841$B^2$)(1-1.424B+0.807$B^2$)(1-1.662$B$+0.742$B^2$)(1+1.155$B$+0.720$B^2$)($X_{t}$ - `r mean(x)`) = (1-0.882B) $a_{t}$  with $\sigma_{a}^2$ = `r est.arma.13.1$avar`**

### Non Stationary Model

BIC suggests an AR(11) and AIC suggests an ARMA(12, 1) of models with options up to ARMA(16, 5).
We will continue with the smaller model AR(11).

```{r}
aicbic(dif1, p = 0:16, silent = T, merge = TRUE, sort_by = 'bic')
```

#### AR(11) Parameter Estimation

```{r}
est.arima.11.1.0.0 <- est.arma.wge(dif1, p = 11, q = 0)
```

#### Factored Form

```{r}
est.arima.11.1.0.0$avar
```

**(1-0.6227$B$+0.8766$B^2$)(1+1.7743$B$+0.8617$B^2$)(1-1.5025$B$+0.8361$B^2$)(1+0.5210$B$+0.8091$B^2$)(1+1.0965$B$+0.6776$B^2$)(1-0.6025$B$)(1 - $B$)($X_{t}$ - `r mean(x)`) = $a_{t}$  with $\sigma_{a}^2$ = `r est.arima.11.1.0.0$avar`**

## Visualizing Model Comparison


```{r}
models = list("ARMA(13,1)" = list(phi = est.arma.13.1$phi,
                                  theta = est.arma.13.1$theta,
                                  vara = est.arma.13.1$avar,
                                  res = est.arma.13.1$res,
                                  sliding_ase = TRUE),
              "ARIMA(11,1,0) s = 0" = list(phi = est.arima.11.1.0.0$phi,
                                     theta = est.arima.11.1.0.0$theta,
                                     d = 1,
                                     s = 0,
                                     vara = est.arima.11.1.0.0$avar,
                                     res = est.arima.11.1.0.0$res,
                                     sliding_ase = TRUE)
              )
```


```{r}
mdl_compare = tswgewrapped::ModelCompareUnivariate$new(data = x, mdl_list = models,
                                                       n.ahead = n.ahead, batch_size = batch_size)
```

### Compare Residuals for White Noise
```{r}
table = mdl_compare$evaluate_residuals()
print(table)
```

### Compare Multiple Realizations

```{r fig.height=8, fig.width=8, message=FALSE, warning=FALSE}
mdl_compare$plot_multiple_realizations(n.realizations = 4, seed = 100, plot = "realization", scales = 'fixed')
```

```{r fig.height=4, message=FALSE, warning=FALSE}
mdl_compare$plot_multiple_realizations(n.realizations = 4, seed = 100, plot = c("acf", "spectrum"), scales = 'fixed')
```

### Compare Simple Forecasts
```{r fig.height=4, fig.width=12}
mdl_compare$plot_simple_forecasts(lastn = FALSE, limits = FALSE)
```

### ASE values across Batches
```{r message=FALSE, warning=FALSE}
ASEs = mdl_compare$get_tabular_metrics(ases = TRUE)
print(ASEs)
```

```{r}
ASEs %>% 
  group_by(Model) %>% 
  summarise(ASE_mean = mean(ASE),
            ASE_median = median(ASE),
            ASE_sd = sd(ASE),
            num_batches = n())
```

```{r message=FALSE, warning=FALSE}
mdl_compare$plot_histogram_ases()
```

### Forecasts across Batches

```{r, warning=FALSE, fig.height=4, fig.width=10}
mdl_compare$plot_batch_forecasts(only_sliding = TRUE)
```

```{r, warning=FALSE, fig.height=4, fig.width=10}
mdl_compare$plot_batch_ases(only_sliding = TRUE)
```

```{r}
forecasts = mdl_compare$get_tabular_metrics(ases = FALSE)
print(forecasts)
```

### Statistical Comparison
```{r}
mdl_compare$statistical_compare()  
```


**CONCLUSION**

* It looks like both model performs pooprly in predicting severe downturns (~ time point 80, 120, 150) and upturns (~ time points 48, 127, 172).
* We may need to inclue exogenous variables into our model that are more indicative of these downturns and upturns in order to improve the model performance.


```{r}

```



