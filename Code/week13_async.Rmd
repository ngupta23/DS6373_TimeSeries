---
title: "Time Series - Async Week 12"
author: "Nikhil Gupta"
date: "`r Sys.time()`"
output:
  word_document:
    toc: yes
    toc_depth: '6'
  html_document:
    toc: yes
    toc_depth: 6
    toc_float: yes
always_allow_html: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Setup
```{r}
library(tswge)
library(tswgewrapped)
library(tidyverse)
library(tseries)
library(orcutt)
library(vars)
library(RColorBrewer)
library(nnfor)
```

# (Univariate) SWDelay Data

```{r}
SWA = read.csv("../Datasets/swadelay.csv")
SWA %>%  glimpse()
```

```{r}
#Divide dataset into training and test set.  The last 36 months in the test set.
SWATrain = ts(SWA$arr_delay[1:141],start= c(2004,1),frequency = 12)
SWATest = ts(SWA$arr_delay[142:177],start = c(2015,10),frequency = 12)
```

## Modeling

### ARIMA(5, 1, 0) s = 12 (auto pick)

```{r}
set.seed(2)
fit.mlp = nnfor::mlp(SWATrain, reps = 50, comb = "mean")
fit.mlp

## difforder is selected automatically (default: NULL) --> picks D1 here
## Univatiate lags also picked automatically (what argument does this come from?)
## Seasonal dummies picked (11 for seasonality = 12)
```

```{r}
# Visualize the Neural Network
# Pink are the seasonal dummies
# Other are univariate lags (5)
# 5 hidden layers
plot(fit.mlp)
```

```{r}
fore.mlp = forecast(fit.mlp, h = 36)
plot(fore.mlp)
# Shows all 50 iterations and then the mean
```

```{r}
ASE = mean((SWATest - fore.mlp$mean)^2)
ASE
```

### AR(12) equivalent

```{r}
set.seed(2)
# Specifying the lags to use and not allow seasonal dummies
# Picks D1 automatically
fit.mlp = mlp(SWATrain, lags = c(1,2,3,4,5,6,7,8,9,10,11,12), allow.det.season = FALSE)
fit.mlp
```

```{r}
plot(fit.mlp)
fore.mlp = forecast(fit.mlp, h = 36)
plot(fore.mlp)
ASE = mean((SWATest - fore.mlp$mean)^2)
ASE
```

### ARIMA(12, 0, 0) with s = 12 (manual)
```{r}
set.seed(2)
fit.mlp = mlp(SWATrain, difforder = c(12), allow.det.season = FALSE)
fit.mlp
```

```{r}
plot(fit.mlp)
fore.mlp = forecast(fit.mlp, h = 36)
plot(fore.mlp)
ASE = mean((SWATest - fore.mlp$mean)^2)
ASE
```

## 13.3 (4)

```{r}
set.seed(2)
fit.mlp = mlp(SWATrain, difforder = c(1,6,12), allow.det.season = FALSE, reps = 100)
fit.mlp
```

```{r}
plot(fit.mlp)
fore.mlp = forecast(fit.mlp, h = 36)
plot(fore.mlp)
ASE = mean((SWATest - fore.mlp$mean)^2)
ASE
```

# (Univariate) Airline Data

```{r}
data("airlog")
```

```{r}
lairTrain = ts(airlog[1:108], frequency = 12, start = c(1949, 1)) # First 108 months in the Training Set.
lairTest = ts(airlog[109:144], frequency = 12, start = c(1958, 1)) # Last 36 months in the Test set. 
```

## Modeling

### Defaults
```{r}
set.seed(2)
fit.mlp = mlp(lairTrain)
fit.mlp
```

```{r}
plot(fit.mlp)
fore.mlp = forecast(fit.mlp, h = 36)
plot(fore.mlp)
ASE = mean((lairTest - fore.mlp$mean)^2)
ASE
```

### Manual s = 12
```{r}
set.seed(2)
fit.mlp = mlp(lairTrain, difforder = c(12))
fit.mlp

## Seasonal dummies not included since we are already specifying the D = 12
```


```{r}
plot(fit.mlp)
fore.mlp = forecast(fit.mlp, h = 36)
plot(fore.mlp)
ASE = mean((lairTest - fore.mlp$mean)^2)
ASE
```

### Manual d = 1, s = 12
```{r}
set.seed(2)
fit.mlp = mlp(lairTrain, difforder = c(1, 12), comb = "mean")
fit.mlp

## Seasonal dummies not included since we are already specifying the D = 12
```


```{r}
plot(fit.mlp)
fore.mlp = forecast(fit.mlp, h = 36)
plot(fore.mlp)
ASE = mean((lairTest - fore.mlp$mean)^2)
ASE
```

## 13.4 

### 2

```{r}
# Default
set.seed(2)
start = proc.time() 
fit.mlp = mlp(lairTrain)
end = proc.time() 
print(paste0("Time taken: ", end[3]-start[3]))
fit.mlp
```

```{r}
# With autoselection of number of layers
set.seed(2)
start = proc.time() 
fit.mlp = mlp(lairTrain, hd.auto.type = 'cv')
end = proc.time() 
print(paste0("Time taken: ", end[3]-start[3]))
fit.mlp
```

### 3

```{r}
plot(fit.mlp)
fore.mlp = forecast(fit.mlp, h = 36)
plot(fore.mlp)
ASE = mean((lairTest - fore.mlp$mean)^2)
ASE
```

# Multivariate (Sales)

```{r}
BS = read.csv("../Datasets/businesssales.csv")
BS %>% glimpse()
```

## Univariate (Only Time as a regressor)
```{r}
#BS is the Business data
tBS80 = ts(BS$sales[1:80])
```

```{r}
set.seed(2)
fit3 = mlp(tBS80)
f = forecast(fit3, h = 20)
plot(BS$sales[81:100],type = "l")
lines(seq(1,20),f$mean, col = "blue")
ASE = mean((BS$sales[81:100]-f$mean)^2)
ASE
```

## Multivariate (With additional Regressors)
```{r}
set.seed(2)
tBS80 = ts(BS$sales[1:80])
tBSx = data.frame(ad_tv = ts(BS$ad_tv), ad_online = ts(BS$ad_online, frequency = 7), discount = ts(BS$discount)) 

## Regressor lags will be picked automatically
fit3 = mlp(tBS80, xreg = tBSx[1:80, ])
# fit3 = mlp(tBS80, xreg = tBSx[1:80, ], lags = 1:10, xreg.lags = (list(1:5, 1:3, 1:6)), keep = c(rep(T, 10)))  # separate lags for every predictor
# fit3

f = forecast(fit3,  h = 20, xreg = tBSx[81:100,])
plot(BS$sales[81:100],type = "l")
lines(seq(1,20),f$mean, col = "blue")
ASE = mean((BS$sales[81:100]-f$mean)^2)
ASE
```

##  MLR with Correlated errors (gives error with forecast function)

```{r}
BS = BS %>% 
  mutate(ad_tv1 = dplyr::lag(ad_tv, 1)) %>% 
  mutate(ad_online1 = dplyr::lag(ad_online, 1)) 

BS
```

```{r}
# Create Lagged Variables
ad_tv1 = c(NA,BS$ad_tv[1:(length(BS$ad_tv)-1)])
ad_online1 = c(NA,BS$ad_online[1:(length(BS$ad_online)-1)])
BS$ad_tv1 = ad_tv1
BS$ad_online1 = ad_online1

# LM fit
ksfit = lm(sales~ad_tv1+ad_online1+discount, data = BS)
aic.wge(ksfit$residuals,p=0:8,q=0:0)  # AIC picks p=7

# ARIMA fit
fit = Arima(BS$sales[1:100], order=c(7,0,0),
            xreg = as.matrix(BS %>%
                               dplyr::select(ad_tv1, ad_online1, discount) %>%
                               dplyr::slice(1:100)))
```

```{r}
# Predictions
preds = forecast(fit, h = 20,  
                 xreg = cbind(BS$ad_tv1[81:100],BS$ad_online1[81:100],BS$discount[81:100]))
# BS %>% 
#    dplyr::select(ad_tv1, ad_online1, discount) %>% 
#    dplyr::slice(81:100)

plot(BS$sales[81:100],type = "l")
lines(seq(1,20),preds$mean, col = "blue")
ASE = mean((BS$sales[81:100]-preds$mean)^2)
ASE
```



(Doing old way from last class - no error with predict function)
But the answer is different from the slide.
```{r}
ksfit = lm(sales ~ ad_tv1 + ad_online1 + discount, data = BS)
aic_fit = aic.wge(ksfit$residuals,p=0:8, q=0)  # AIC picks p=7

fit = arima(BS$sales, order=c(aic_fit$p,0,0), xreg= BS %>% dplyr::select(ad_tv1, ad_online1, discount))

```

```{r}
preds = predict(fit, newxreg = cbind(BS$ad_tv1[81:100],BS$ad_online1[81:100],BS$discount[81:100]))
plot(BS$sales[81:100],type = "l")
lines(seq(1,20),preds$pred, col = "blue")
ASE1 = mean((BS$sales[81:100] - preds$pred)^2)
ASE1
```

## 13.5 (2)
```{r}
set.seed(2)
tBS80 = ts(BS$sales[1:80])
tBSx = data.frame(ad_tv = ts(BS$ad_tv), ad_online = ts(BS$ad_online, frequency = 7), discount = ts(BS$discount)) 

## Regressor lags will be picked automatically
fit3 = mlp(tBS80, xreg = tBSx, hd.auto.type = 'cv')
fit3
```


```{r}
f = forecast(fit3, h = 20, xreg = tBSx)
plot(BS$sales[81:100],type = "l")
lines(seq(1,20),f$mean, col = "blue")
ASE = mean((BS$sales[81:100]-f$mean)^2)
ASE
```

